{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11929676,"sourceType":"datasetVersion","datasetId":7500056}],"dockerImageVersionId":31042,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Imports libraries \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.metrics import (\n    accuracy_score, roc_auc_score, recall_score, f1_score,\n    confusion_matrix\n)\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T11:02:45.129291Z","iopub.execute_input":"2025-05-31T11:02:45.129983Z","iopub.status.idle":"2025-05-31T11:02:45.134415Z","shell.execute_reply.started":"2025-05-31T11:02:45.129960Z","shell.execute_reply":"2025-05-31T11:02:45.133778Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"#  Load Dataset\ntrain_df = pd.read_csv(\"/kaggle/input/naamii-task-2-dataset/TASK_2/train_set.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/naamii-task-2-dataset/TASK_2/test_set.csv\")\nblinded_test_df = pd.read_csv(\"/kaggle/input/naamii-task-2-dataset/TASK_2/blinded_test_set.csv\")\n\n# Preprocessing \nX_train = train_df.drop(columns=[\"ID\", \"CLASS\"])\ny_train = train_df[\"CLASS\"]\nX_test = test_df.drop(columns=[\"ID\", \"CLASS\"])\ny_test = test_df[\"CLASS\"]\nX_blinded = blinded_test_df.drop(columns=[\"ID\"])\n\ntrain_ids = train_df[\"ID\"]\ntest_ids = test_df[\"ID\"]\nblinded_ids = blinded_test_df[\"ID\"]\n\n# Handle inf values\nfor df in [X_train, X_test, X_blinded]:\n    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n\n# Define preprocessing pipeline\nnumeric_features = X_train.columns.tolist()\nnumeric_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n    (\"scaler\", StandardScaler())\n])\npreprocessor = ColumnTransformer([\n    (\"num\", numeric_pipeline, numeric_features)\n])\n\n# Apply preprocessing\nX_train_processed = preprocessor.fit_transform(X_train)\nX_test_processed = preprocessor.transform(X_test)\nX_blinded_processed = preprocessor.transform(X_blinded)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T11:03:31.585556Z","iopub.execute_input":"2025-05-31T11:03:31.586061Z","iopub.status.idle":"2025-05-31T11:03:32.183491Z","shell.execute_reply.started":"2025-05-31T11:03:31.586038Z","shell.execute_reply":"2025-05-31T11:03:32.182993Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Evaluation Function \ndef get_metrics(model, X, y_true):\n    y_pred = model.predict(X)\n    y_prob = model.predict_proba(X)[:, 1]\n    acc = accuracy_score(y_true, y_pred)\n    auc = roc_auc_score(y_true, y_prob)\n    recall = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n    specificity = tn / (tn + fp)\n    return {\n        \"Accuracy\": acc,\n        \"AUROC\": auc,\n        \"Sensitivity\": recall,\n        \"Specificity\": specificity,\n        \"F1-score\": f1\n    }\n\ndef save_probabilities_csv(model, X, ids, filename):\n    probs = model.predict_proba(X)\n    prob_df = pd.DataFrame(probs, columns=[\"Class_0_Prob\", \"Class_1_Prob\"])\n    prob_df.insert(0, \"ID\", ids.values)\n    prob_df.to_csv(filename, index=False)\n\n# Model Training & Evaluation \n\nresults = {}\n\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T11:04:32.419168Z","iopub.execute_input":"2025-05-31T11:04:32.419724Z","iopub.status.idle":"2025-05-31T11:04:32.425107Z","shell.execute_reply.started":"2025-05-31T11:04:32.419702Z","shell.execute_reply":"2025-05-31T11:04:32.424450Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Logistic Regression \nlog_reg = LogisticRegression(max_iter=1000, solver='liblinear')\nlog_reg.fit(X_train_processed, y_train)\nresults['Logistic Regression'] = {\n    \"Train\": get_metrics(log_reg, X_train_processed, y_train),\n    \"Test\": get_metrics(log_reg, X_test_processed, y_test)\n}\n\n# Random Forest \nrf_grid = {\n    \"n_estimators\": [100],\n    \"max_depth\": [10, 20],\n    \"min_samples_split\": [2, 5]\n}\nrf_model = GridSearchCV(RandomForestClassifier(random_state=42), rf_grid, cv=cv,\n                        scoring='roc_auc', n_jobs=-1)\nrf_model.fit(X_train_processed, y_train)\nrf_best = rf_model.best_estimator_\nresults['Random Forest'] = {\n    \"Train\": get_metrics(rf_best, X_train_processed, y_train),\n    \"Test\": get_metrics(rf_best, X_test_processed, y_test)\n}\n\n#  XGBoost \nxgb_grid = {\n    \"n_estimators\": [100],\n    \"max_depth\": [3, 5],\n    \"learning_rate\": [0.1, 0.05]\n}\nxgb_model = GridSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n                         xgb_grid, cv=cv, scoring='roc_auc', n_jobs=-1)\nxgb_model.fit(X_train_processed, y_train)\nxgb_best = xgb_model.best_estimator_\nresults['XGBoost'] = {\n    \"Train\": get_metrics(xgb_best, X_train_processed, y_train),\n    \"Test\": get_metrics(xgb_best, X_test_processed, y_test)\n}\n\n#  Final Class-Probability CSVs \nsave_probabilities_csv(xgb_best, X_train_processed, train_ids, \"train_predictions.csv\")\nsave_probabilities_csv(xgb_best, X_test_processed, test_ids, \"test_predictions.csv\")\nsave_probabilities_csv(xgb_best, X_blinded_processed, blinded_ids, \"blinded_test_predictions.csv\")\n\n\n#  Results Table \nprint(\"\\nFinal Evaluation Results (Train & Test Sets):\\n\")\nresults_df = pd.DataFrame([\n    {\n        \"Model\": model,\n        \"Dataset\": dataset,\n        **metrics\n    }\n    for model, model_results in results.items()\n    for dataset, metrics in model_results.items()\n])\nprint(results_df.round(4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T11:05:19.540534Z","iopub.execute_input":"2025-05-31T11:05:19.541123Z","iopub.status.idle":"2025-05-31T11:07:33.541711Z","shell.execute_reply.started":"2025-05-31T11:05:19.541098Z","shell.execute_reply":"2025-05-31T11:07:33.541144Z"}},"outputs":[{"name":"stdout","text":"\nFinal Evaluation Results (Train & Test Sets):\n\n                 Model Dataset  Accuracy   AUROC  Sensitivity  Specificity  \\\n0  Logistic Regression   Train      1.00  1.0000       1.0000       1.0000   \n1  Logistic Regression    Test      0.59  0.6466       0.4524       0.6897   \n2        Random Forest   Train      1.00  1.0000       1.0000       1.0000   \n3        Random Forest    Test      0.63  0.6708       0.3095       0.8621   \n4              XGBoost   Train      1.00  1.0000       1.0000       1.0000   \n5              XGBoost    Test      0.61  0.6326       0.3571       0.7931   \n\n   F1-score  \n0    1.0000  \n1    0.4810  \n2    1.0000  \n3    0.4127  \n4    1.0000  \n5    0.4348  \n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#display initial rows\n\ndisplay(train_df.head())\ndisplay(test_df.head())\ndisplay(blinded_test_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T10:45:36.817251Z","iopub.execute_input":"2025-05-31T10:45:36.818010Z","iopub.status.idle":"2025-05-31T10:45:36.897398Z","shell.execute_reply.started":"2025-05-31T10:45:36.817973Z","shell.execute_reply":"2025-05-31T10:45:36.896711Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"     ID     Feature_1  Feature_2     Feature_3  Feature_4  Feature_5  \\\n0  ID_1  18281.541667    18432.0   9409.650391   0.514708   0.011300   \n1  ID_2  20010.083333    20100.0   8303.049072   0.417707   0.014959   \n2  ID_3  27260.125000    27437.0  12189.649414   0.447160   0.011428   \n3  ID_4  41938.125000    42138.0  17866.433594   0.426019   0.009908   \n4  ID_5  41274.125000    41439.0  14315.041992   0.346828   0.013596   \n\n   Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_3230  \\\n0   0.045369   2.803803   0.356658   1.803803  ...    382.968383   \n1   0.080294   2.338398   0.429532   1.338398  ...    452.986164   \n2   0.046402   2.782842   0.359345   1.782842  ...    419.781765   \n3   0.034878   3.060655   0.326727   2.060655  ...    439.023968   \n4   0.065680   2.478506   0.403469   1.478506  ...    485.209184   \n\n   Feature_3231  Feature_3232  Feature_3233  Feature_3234  Feature_3235  \\\n0        2214.0           1.0    136.625113      0.061710           0.0   \n1        2548.5           1.0    232.564022      0.090548           0.0   \n2        3400.0           1.0    233.593529      0.068704           0.0   \n3        5424.0           1.0    427.429572      0.078803           0.0   \n4        5096.0           1.0    726.731554      0.142608           0.0   \n\n   Feature_3236  Feature_3237  Feature_3238  CLASS  \n0     28.154838      4.174959      0.061710      0  \n1     27.934229      3.931950      0.090548      1  \n2     27.904807      4.085035      0.068704      1  \n3     27.870588      4.011726      0.078803      0  \n4     28.846909      3.571352      0.142608      0  \n\n[5 rows x 3240 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Feature_1</th>\n      <th>Feature_2</th>\n      <th>Feature_3</th>\n      <th>Feature_4</th>\n      <th>Feature_5</th>\n      <th>Feature_6</th>\n      <th>Feature_7</th>\n      <th>Feature_8</th>\n      <th>Feature_9</th>\n      <th>...</th>\n      <th>Feature_3230</th>\n      <th>Feature_3231</th>\n      <th>Feature_3232</th>\n      <th>Feature_3233</th>\n      <th>Feature_3234</th>\n      <th>Feature_3235</th>\n      <th>Feature_3236</th>\n      <th>Feature_3237</th>\n      <th>Feature_3238</th>\n      <th>CLASS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_1</td>\n      <td>18281.541667</td>\n      <td>18432.0</td>\n      <td>9409.650391</td>\n      <td>0.514708</td>\n      <td>0.011300</td>\n      <td>0.045369</td>\n      <td>2.803803</td>\n      <td>0.356658</td>\n      <td>1.803803</td>\n      <td>...</td>\n      <td>382.968383</td>\n      <td>2214.0</td>\n      <td>1.0</td>\n      <td>136.625113</td>\n      <td>0.061710</td>\n      <td>0.0</td>\n      <td>28.154838</td>\n      <td>4.174959</td>\n      <td>0.061710</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_2</td>\n      <td>20010.083333</td>\n      <td>20100.0</td>\n      <td>8303.049072</td>\n      <td>0.417707</td>\n      <td>0.014959</td>\n      <td>0.080294</td>\n      <td>2.338398</td>\n      <td>0.429532</td>\n      <td>1.338398</td>\n      <td>...</td>\n      <td>452.986164</td>\n      <td>2548.5</td>\n      <td>1.0</td>\n      <td>232.564022</td>\n      <td>0.090548</td>\n      <td>0.0</td>\n      <td>27.934229</td>\n      <td>3.931950</td>\n      <td>0.090548</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_3</td>\n      <td>27260.125000</td>\n      <td>27437.0</td>\n      <td>12189.649414</td>\n      <td>0.447160</td>\n      <td>0.011428</td>\n      <td>0.046402</td>\n      <td>2.782842</td>\n      <td>0.359345</td>\n      <td>1.782842</td>\n      <td>...</td>\n      <td>419.781765</td>\n      <td>3400.0</td>\n      <td>1.0</td>\n      <td>233.593529</td>\n      <td>0.068704</td>\n      <td>0.0</td>\n      <td>27.904807</td>\n      <td>4.085035</td>\n      <td>0.068704</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_4</td>\n      <td>41938.125000</td>\n      <td>42138.0</td>\n      <td>17866.433594</td>\n      <td>0.426019</td>\n      <td>0.009908</td>\n      <td>0.034878</td>\n      <td>3.060655</td>\n      <td>0.326727</td>\n      <td>2.060655</td>\n      <td>...</td>\n      <td>439.023968</td>\n      <td>5424.0</td>\n      <td>1.0</td>\n      <td>427.429572</td>\n      <td>0.078803</td>\n      <td>0.0</td>\n      <td>27.870588</td>\n      <td>4.011726</td>\n      <td>0.078803</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_5</td>\n      <td>41274.125000</td>\n      <td>41439.0</td>\n      <td>14315.041992</td>\n      <td>0.346828</td>\n      <td>0.013596</td>\n      <td>0.065680</td>\n      <td>2.478506</td>\n      <td>0.403469</td>\n      <td>1.478506</td>\n      <td>...</td>\n      <td>485.209184</td>\n      <td>5096.0</td>\n      <td>1.0</td>\n      <td>726.731554</td>\n      <td>0.142608</td>\n      <td>0.0</td>\n      <td>28.846909</td>\n      <td>3.571352</td>\n      <td>0.142608</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 3240 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"     ID     Feature_1  Feature_2     Feature_3  Feature_4  Feature_5  \\\n0  ID_1  15385.458333    15472.5   6357.250488   0.413973   0.017592   \n1  ID_2  19539.729167    19651.5   8168.700928   0.417849   0.014973   \n2  ID_3  34867.125000    35049.0  14382.916992   0.412507   0.011404   \n3  ID_4  46112.083333    46290.0  16512.630859   0.358098   0.012261   \n4  ID_5  37229.000000    37383.0  12981.727539   0.348699   0.014201   \n\n   Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_3230  \\\n0   0.111930   2.108410   0.478124   1.108410  ...    444.535442   \n1   0.079801   2.326599   0.430171   1.326599  ...    450.784676   \n2   0.046211   2.786669   0.358851   1.786669  ...    439.605257   \n3   0.053411   2.655353   0.376598   1.655353  ...    477.467085   \n4   0.071650   2.407654   0.415342   1.407654  ...    488.478334   \n\n   Feature_3231  Feature_3232  Feature_3233  Feature_3234  Feature_3235  \\\n0        1934.5           1.0    170.507074      0.086972           0.0   \n1        2480.5           1.0    234.801218      0.094857           0.0   \n2        4299.0           1.0    449.882066      0.104648           0.0   \n3        5742.0           1.0    706.494949      0.123040           0.0   \n4        4754.0           1.0    650.593185      0.136852           0.0   \n\n   Feature_3236  Feature_3237  Feature_3238  CLASS  \n0     29.952211      3.963248      0.086972      1  \n1     31.625858      3.942665      0.094857      0  \n2     28.805248      3.788374      0.104648      0  \n3     27.601655      3.675757      0.123040      0  \n4     28.207070      3.620278      0.136852      0  \n\n[5 rows x 3240 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Feature_1</th>\n      <th>Feature_2</th>\n      <th>Feature_3</th>\n      <th>Feature_4</th>\n      <th>Feature_5</th>\n      <th>Feature_6</th>\n      <th>Feature_7</th>\n      <th>Feature_8</th>\n      <th>Feature_9</th>\n      <th>...</th>\n      <th>Feature_3230</th>\n      <th>Feature_3231</th>\n      <th>Feature_3232</th>\n      <th>Feature_3233</th>\n      <th>Feature_3234</th>\n      <th>Feature_3235</th>\n      <th>Feature_3236</th>\n      <th>Feature_3237</th>\n      <th>Feature_3238</th>\n      <th>CLASS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_1</td>\n      <td>15385.458333</td>\n      <td>15472.5</td>\n      <td>6357.250488</td>\n      <td>0.413973</td>\n      <td>0.017592</td>\n      <td>0.111930</td>\n      <td>2.108410</td>\n      <td>0.478124</td>\n      <td>1.108410</td>\n      <td>...</td>\n      <td>444.535442</td>\n      <td>1934.5</td>\n      <td>1.0</td>\n      <td>170.507074</td>\n      <td>0.086972</td>\n      <td>0.0</td>\n      <td>29.952211</td>\n      <td>3.963248</td>\n      <td>0.086972</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_2</td>\n      <td>19539.729167</td>\n      <td>19651.5</td>\n      <td>8168.700928</td>\n      <td>0.417849</td>\n      <td>0.014973</td>\n      <td>0.079801</td>\n      <td>2.326599</td>\n      <td>0.430171</td>\n      <td>1.326599</td>\n      <td>...</td>\n      <td>450.784676</td>\n      <td>2480.5</td>\n      <td>1.0</td>\n      <td>234.801218</td>\n      <td>0.094857</td>\n      <td>0.0</td>\n      <td>31.625858</td>\n      <td>3.942665</td>\n      <td>0.094857</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_3</td>\n      <td>34867.125000</td>\n      <td>35049.0</td>\n      <td>14382.916992</td>\n      <td>0.412507</td>\n      <td>0.011404</td>\n      <td>0.046211</td>\n      <td>2.786669</td>\n      <td>0.358851</td>\n      <td>1.786669</td>\n      <td>...</td>\n      <td>439.605257</td>\n      <td>4299.0</td>\n      <td>1.0</td>\n      <td>449.882066</td>\n      <td>0.104648</td>\n      <td>0.0</td>\n      <td>28.805248</td>\n      <td>3.788374</td>\n      <td>0.104648</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_4</td>\n      <td>46112.083333</td>\n      <td>46290.0</td>\n      <td>16512.630859</td>\n      <td>0.358098</td>\n      <td>0.012261</td>\n      <td>0.053411</td>\n      <td>2.655353</td>\n      <td>0.376598</td>\n      <td>1.655353</td>\n      <td>...</td>\n      <td>477.467085</td>\n      <td>5742.0</td>\n      <td>1.0</td>\n      <td>706.494949</td>\n      <td>0.123040</td>\n      <td>0.0</td>\n      <td>27.601655</td>\n      <td>3.675757</td>\n      <td>0.123040</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_5</td>\n      <td>37229.000000</td>\n      <td>37383.0</td>\n      <td>12981.727539</td>\n      <td>0.348699</td>\n      <td>0.014201</td>\n      <td>0.071650</td>\n      <td>2.407654</td>\n      <td>0.415342</td>\n      <td>1.407654</td>\n      <td>...</td>\n      <td>488.478334</td>\n      <td>4754.0</td>\n      <td>1.0</td>\n      <td>650.593185</td>\n      <td>0.136852</td>\n      <td>0.0</td>\n      <td>28.207070</td>\n      <td>3.620278</td>\n      <td>0.136852</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 3240 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"       ID     Feature_1  Feature_2     Feature_3  Feature_4  Feature_5  \\\n0  ID_101  13249.250000    13323.0   5322.087891   0.401690   0.019253   \n1  ID_102  60593.666667    60804.0  21327.521484   0.351976   0.010976   \n2  ID_103  51978.833333    52193.0  19574.339844   0.376583   0.010708   \n3  ID_104  47737.416667    47943.0  17247.173828   0.361293   0.011891   \n4  ID_105  33029.458333    33261.0  15901.136719   0.481423   0.009294   \n\n   Feature_6  Feature_7  Feature_8  Feature_9  ...  Feature_3229  \\\n0   0.131701   1.965488   0.508780   0.965488  ...    453.349939   \n1   0.042804   2.858719   0.349807   1.858719  ...    492.250478   \n2   0.040742   2.906154   0.344097   1.906154  ...    482.387417   \n3   0.050236   2.710158   0.368982   1.710158  ...    475.620243   \n4   0.030688   3.194060   0.313081   2.194060  ...    417.949466   \n\n   Feature_3230  Feature_3231  Feature_3232  Feature_3233  Feature_3234  \\\n0    453.349939        1646.0           1.0    162.029162      0.098438   \n1    492.250478        7853.0           1.0    961.759455      0.122470   \n2    482.387417        6644.0           1.0    763.046057      0.114847   \n3    475.620243        6017.0           1.0    718.741732      0.119452   \n4    417.949466        4116.0           1.0    314.568513      0.076426   \n\n   Feature_3235  Feature_3236  Feature_3237  Feature_3238  \n0           0.0     30.580378      3.888605      0.098438  \n1           0.0     26.690038      3.695084      0.122470  \n2           0.0     30.037774      3.804517      0.114847  \n3           0.0     27.964103      3.699860      0.119452  \n4           0.0     31.802140      4.078748      0.076426  \n\n[5 rows x 3239 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Feature_1</th>\n      <th>Feature_2</th>\n      <th>Feature_3</th>\n      <th>Feature_4</th>\n      <th>Feature_5</th>\n      <th>Feature_6</th>\n      <th>Feature_7</th>\n      <th>Feature_8</th>\n      <th>Feature_9</th>\n      <th>...</th>\n      <th>Feature_3229</th>\n      <th>Feature_3230</th>\n      <th>Feature_3231</th>\n      <th>Feature_3232</th>\n      <th>Feature_3233</th>\n      <th>Feature_3234</th>\n      <th>Feature_3235</th>\n      <th>Feature_3236</th>\n      <th>Feature_3237</th>\n      <th>Feature_3238</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ID_101</td>\n      <td>13249.250000</td>\n      <td>13323.0</td>\n      <td>5322.087891</td>\n      <td>0.401690</td>\n      <td>0.019253</td>\n      <td>0.131701</td>\n      <td>1.965488</td>\n      <td>0.508780</td>\n      <td>0.965488</td>\n      <td>...</td>\n      <td>453.349939</td>\n      <td>453.349939</td>\n      <td>1646.0</td>\n      <td>1.0</td>\n      <td>162.029162</td>\n      <td>0.098438</td>\n      <td>0.0</td>\n      <td>30.580378</td>\n      <td>3.888605</td>\n      <td>0.098438</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ID_102</td>\n      <td>60593.666667</td>\n      <td>60804.0</td>\n      <td>21327.521484</td>\n      <td>0.351976</td>\n      <td>0.010976</td>\n      <td>0.042804</td>\n      <td>2.858719</td>\n      <td>0.349807</td>\n      <td>1.858719</td>\n      <td>...</td>\n      <td>492.250478</td>\n      <td>492.250478</td>\n      <td>7853.0</td>\n      <td>1.0</td>\n      <td>961.759455</td>\n      <td>0.122470</td>\n      <td>0.0</td>\n      <td>26.690038</td>\n      <td>3.695084</td>\n      <td>0.122470</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ID_103</td>\n      <td>51978.833333</td>\n      <td>52193.0</td>\n      <td>19574.339844</td>\n      <td>0.376583</td>\n      <td>0.010708</td>\n      <td>0.040742</td>\n      <td>2.906154</td>\n      <td>0.344097</td>\n      <td>1.906154</td>\n      <td>...</td>\n      <td>482.387417</td>\n      <td>482.387417</td>\n      <td>6644.0</td>\n      <td>1.0</td>\n      <td>763.046057</td>\n      <td>0.114847</td>\n      <td>0.0</td>\n      <td>30.037774</td>\n      <td>3.804517</td>\n      <td>0.114847</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ID_104</td>\n      <td>47737.416667</td>\n      <td>47943.0</td>\n      <td>17247.173828</td>\n      <td>0.361293</td>\n      <td>0.011891</td>\n      <td>0.050236</td>\n      <td>2.710158</td>\n      <td>0.368982</td>\n      <td>1.710158</td>\n      <td>...</td>\n      <td>475.620243</td>\n      <td>475.620243</td>\n      <td>6017.0</td>\n      <td>1.0</td>\n      <td>718.741732</td>\n      <td>0.119452</td>\n      <td>0.0</td>\n      <td>27.964103</td>\n      <td>3.699860</td>\n      <td>0.119452</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ID_105</td>\n      <td>33029.458333</td>\n      <td>33261.0</td>\n      <td>15901.136719</td>\n      <td>0.481423</td>\n      <td>0.009294</td>\n      <td>0.030688</td>\n      <td>3.194060</td>\n      <td>0.313081</td>\n      <td>2.194060</td>\n      <td>...</td>\n      <td>417.949466</td>\n      <td>417.949466</td>\n      <td>4116.0</td>\n      <td>1.0</td>\n      <td>314.568513</td>\n      <td>0.076426</td>\n      <td>0.0</td>\n      <td>31.802140</td>\n      <td>4.078748</td>\n      <td>0.076426</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 3239 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# overview of data types and nulls\n\ndef dataset_summary(df, name = \"Dataset\"):\n    print(f\"\\n{name} Info:\")\n    print(df.info())\n    print(\"\\nMissing Values:\")\n    print(df.isnull().sum())\n    print(\"\\nDescriptive statistics:\")\n    display(df.describe(include = 'all'))\n\n\ndataset_summary(train_df, \"Train Set\")\ndataset_summary(test_df, \"Test Set\")\ndataset_summary(blinded_test_df, \"Blinded Test Set\")\n\n#visualize class distribution \nif 'CLASS' in train_df.columns:\n    sns.countplot(data= train_df, x = 'CLASS')\n    plt.title(\"Class distribution in Training Set\")\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T10:45:50.144185Z","iopub.execute_input":"2025-05-31T10:45:50.144737Z","iopub.status.idle":"2025-05-31T10:46:00.596602Z","shell.execute_reply.started":"2025-05-31T10:45:50.144711Z","shell.execute_reply":"2025-05-31T10:46:00.595846Z"}},"outputs":[{"name":"stdout","text":"\nTrain Set Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 315 entries, 0 to 314\nColumns: 3240 entries, ID to CLASS\ndtypes: float64(3238), int64(1), object(1)\nmemory usage: 7.8+ MB\nNone\n\nMissing Values:\nID              0\nFeature_1       0\nFeature_2       0\nFeature_3       0\nFeature_4       0\n               ..\nFeature_3235    0\nFeature_3236    0\nFeature_3237    0\nFeature_3238    0\nCLASS           0\nLength: 3240, dtype: int64\n\nDescriptive statistics:\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"            ID      Feature_1      Feature_2     Feature_3   Feature_4  \\\ncount      315     315.000000     315.000000    315.000000  315.000000   \nunique     315            NaN            NaN           NaN         NaN   \ntop     ID_315            NaN            NaN           NaN         NaN   \nfreq         1            NaN            NaN           NaN         NaN   \nmean       NaN   36401.611839   36558.978836  13421.797935    0.399783   \nstd        NaN   23979.228698   24006.711019   5229.346354    0.064272   \nmin        NaN    4601.166667    4646.000000   2420.351481    0.137726   \n25%        NaN   23287.562500   23443.500000  10245.704590    0.357646   \n50%        NaN   34818.166667   35028.000000  13894.792969    0.394076   \n75%        NaN   45575.708333   45750.000000  16633.839844    0.434799   \nmax        NaN  332120.750000  332379.000000  45741.601562    0.643473   \n\n         Feature_5   Feature_6   Feature_7   Feature_8   Feature_9  ...  \\\ncount   315.000000  315.000000  315.000000  315.000000  315.000000  ...   \nunique         NaN         NaN         NaN         NaN         NaN  ...   \ntop            NaN         NaN         NaN         NaN         NaN  ...   \nfreq           NaN         NaN         NaN         NaN         NaN  ...   \nmean      0.013326    0.066770    2.572654    0.395949    1.572654  ...   \nstd       0.002885    0.034442    0.305500    0.054492    0.305500  ...   \nmin       0.008904    0.028169    1.684709    0.304269    0.684709  ...   \n25%       0.011459    0.046652    2.403035    0.359990    1.403035  ...   \n50%       0.012477    0.055314    2.624547    0.381018    1.624547  ...   \n75%       0.014242    0.072065    2.777867    0.416141    1.777867  ...   \nmax       0.025418    0.266032    3.286567    0.603905    2.286567  ...   \n\n        Feature_3230  Feature_3231  Feature_3232  Feature_3233  Feature_3234  \\\ncount     315.000000    315.000000         315.0    315.000000    315.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean      458.273347   4580.805291           1.0    620.374167      0.112015   \nstd        39.628050   2980.121623           0.0   1254.417871      0.043563   \nmin       309.374029    591.333333           1.0     45.791124      0.058477   \n25%       432.298489   2881.000000           1.0    245.299821      0.083622   \n50%       460.598280   4377.000000           1.0    424.561776      0.103960   \n75%       484.566083   5769.000000           1.0    702.791528      0.131579   \nmax       636.069588  40797.000000           1.0  20921.640194      0.512823   \n\n        Feature_3235  Feature_3236  Feature_3237  Feature_3238       CLASS  \ncount          315.0    315.000000    315.000000    315.000000  315.000000  \nunique           NaN           NaN           NaN           NaN         NaN  \ntop              NaN           NaN           NaN           NaN         NaN  \nfreq             NaN           NaN           NaN           NaN         NaN  \nmean             0.0     28.510670      3.792381      0.112015    0.393651  \nstd              0.0      1.711272      0.257607      0.043563    0.489336  \nmin              0.0     16.430985      1.995746      0.058477    0.000000  \n25%              0.0     27.691774      3.655440      0.083622    0.000000  \n50%              0.0     28.424340      3.815115      0.103960    0.000000  \n75%              0.0     29.450389      3.963320      0.131579    1.000000  \nmax              0.0     35.149153      4.271132      0.512823    1.000000  \n\n[11 rows x 3240 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Feature_1</th>\n      <th>Feature_2</th>\n      <th>Feature_3</th>\n      <th>Feature_4</th>\n      <th>Feature_5</th>\n      <th>Feature_6</th>\n      <th>Feature_7</th>\n      <th>Feature_8</th>\n      <th>Feature_9</th>\n      <th>...</th>\n      <th>Feature_3230</th>\n      <th>Feature_3231</th>\n      <th>Feature_3232</th>\n      <th>Feature_3233</th>\n      <th>Feature_3234</th>\n      <th>Feature_3235</th>\n      <th>Feature_3236</th>\n      <th>Feature_3237</th>\n      <th>Feature_3238</th>\n      <th>CLASS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>315</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n      <td>...</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n      <td>315.0</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n      <td>315.0</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n      <td>315.000000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>315</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>ID_315</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>36401.611839</td>\n      <td>36558.978836</td>\n      <td>13421.797935</td>\n      <td>0.399783</td>\n      <td>0.013326</td>\n      <td>0.066770</td>\n      <td>2.572654</td>\n      <td>0.395949</td>\n      <td>1.572654</td>\n      <td>...</td>\n      <td>458.273347</td>\n      <td>4580.805291</td>\n      <td>1.0</td>\n      <td>620.374167</td>\n      <td>0.112015</td>\n      <td>0.0</td>\n      <td>28.510670</td>\n      <td>3.792381</td>\n      <td>0.112015</td>\n      <td>0.393651</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>23979.228698</td>\n      <td>24006.711019</td>\n      <td>5229.346354</td>\n      <td>0.064272</td>\n      <td>0.002885</td>\n      <td>0.034442</td>\n      <td>0.305500</td>\n      <td>0.054492</td>\n      <td>0.305500</td>\n      <td>...</td>\n      <td>39.628050</td>\n      <td>2980.121623</td>\n      <td>0.0</td>\n      <td>1254.417871</td>\n      <td>0.043563</td>\n      <td>0.0</td>\n      <td>1.711272</td>\n      <td>0.257607</td>\n      <td>0.043563</td>\n      <td>0.489336</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>4601.166667</td>\n      <td>4646.000000</td>\n      <td>2420.351481</td>\n      <td>0.137726</td>\n      <td>0.008904</td>\n      <td>0.028169</td>\n      <td>1.684709</td>\n      <td>0.304269</td>\n      <td>0.684709</td>\n      <td>...</td>\n      <td>309.374029</td>\n      <td>591.333333</td>\n      <td>1.0</td>\n      <td>45.791124</td>\n      <td>0.058477</td>\n      <td>0.0</td>\n      <td>16.430985</td>\n      <td>1.995746</td>\n      <td>0.058477</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>23287.562500</td>\n      <td>23443.500000</td>\n      <td>10245.704590</td>\n      <td>0.357646</td>\n      <td>0.011459</td>\n      <td>0.046652</td>\n      <td>2.403035</td>\n      <td>0.359990</td>\n      <td>1.403035</td>\n      <td>...</td>\n      <td>432.298489</td>\n      <td>2881.000000</td>\n      <td>1.0</td>\n      <td>245.299821</td>\n      <td>0.083622</td>\n      <td>0.0</td>\n      <td>27.691774</td>\n      <td>3.655440</td>\n      <td>0.083622</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>34818.166667</td>\n      <td>35028.000000</td>\n      <td>13894.792969</td>\n      <td>0.394076</td>\n      <td>0.012477</td>\n      <td>0.055314</td>\n      <td>2.624547</td>\n      <td>0.381018</td>\n      <td>1.624547</td>\n      <td>...</td>\n      <td>460.598280</td>\n      <td>4377.000000</td>\n      <td>1.0</td>\n      <td>424.561776</td>\n      <td>0.103960</td>\n      <td>0.0</td>\n      <td>28.424340</td>\n      <td>3.815115</td>\n      <td>0.103960</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>45575.708333</td>\n      <td>45750.000000</td>\n      <td>16633.839844</td>\n      <td>0.434799</td>\n      <td>0.014242</td>\n      <td>0.072065</td>\n      <td>2.777867</td>\n      <td>0.416141</td>\n      <td>1.777867</td>\n      <td>...</td>\n      <td>484.566083</td>\n      <td>5769.000000</td>\n      <td>1.0</td>\n      <td>702.791528</td>\n      <td>0.131579</td>\n      <td>0.0</td>\n      <td>29.450389</td>\n      <td>3.963320</td>\n      <td>0.131579</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>332120.750000</td>\n      <td>332379.000000</td>\n      <td>45741.601562</td>\n      <td>0.643473</td>\n      <td>0.025418</td>\n      <td>0.266032</td>\n      <td>3.286567</td>\n      <td>0.603905</td>\n      <td>2.286567</td>\n      <td>...</td>\n      <td>636.069588</td>\n      <td>40797.000000</td>\n      <td>1.0</td>\n      <td>20921.640194</td>\n      <td>0.512823</td>\n      <td>0.0</td>\n      <td>35.149153</td>\n      <td>4.271132</td>\n      <td>0.512823</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>11 rows × 3240 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nTest Set Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 100 entries, 0 to 99\nColumns: 3240 entries, ID to CLASS\ndtypes: float64(3238), int64(1), object(1)\nmemory usage: 2.5+ MB\nNone\n\nMissing Values:\nID              0\nFeature_1       0\nFeature_2       0\nFeature_3       0\nFeature_4       0\n               ..\nFeature_3235    0\nFeature_3236    0\nFeature_3237    0\nFeature_3238    0\nCLASS           0\nLength: 3240, dtype: int64\n\nDescriptive statistics:\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"            ID     Feature_1     Feature_2     Feature_3   Feature_4  \\\ncount      100    100.000000    100.000000    100.000000  100.000000   \nunique     100           NaN           NaN           NaN         NaN   \ntop     ID_100           NaN           NaN           NaN         NaN   \nfreq         1           NaN           NaN           NaN         NaN   \nmean       NaN  36053.786458  36214.821667  13592.064411    0.396674   \nstd        NaN  15327.976819  15355.686383   4319.053890    0.059999   \nmin        NaN   6218.729167   6297.000000   3841.149780    0.218619   \n25%        NaN  25357.187500  25519.000000  10880.779541    0.358070   \n50%        NaN  35002.104167  35176.500000  14217.937988    0.389202   \n75%        NaN  43567.947917  43737.500000  15871.476562    0.425203   \nmax        NaN  98935.750000  99113.000000  22896.642578    0.617324   \n\n         Feature_5   Feature_6   Feature_7   Feature_8   Feature_9  ...  \\\ncount   100.000000  100.000000  100.000000  100.000000  100.000000  ...   \nunique         NaN         NaN         NaN         NaN         NaN  ...   \ntop            NaN         NaN         NaN         NaN         NaN  ...   \nfreq           NaN         NaN         NaN         NaN         NaN  ...   \nmean      0.013031    0.063118    2.600435    0.390476    1.600435  ...   \nstd       0.002661    0.029819    0.290887    0.050831    0.290887  ...   \nmin       0.008883    0.028036    1.794599    0.303790    0.794599  ...   \n25%       0.011479    0.046821    2.528735    0.360423    1.528735  ...   \n50%       0.012330    0.054013    2.645460    0.378006    1.645460  ...   \n75%       0.013193    0.061849    2.774520    0.395462    1.774520  ...   \nmax       0.022099    0.173813    3.291749    0.557652    2.291749  ...   \n\n        Feature_3230  Feature_3231  Feature_3232  Feature_3233  Feature_3234  \\\ncount     100.000000    100.000000         100.0    100.000000    100.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean      459.472339   4561.901667           1.0    559.835599      0.110281   \nstd        36.402913   1956.770922           0.0    503.131803      0.038825   \nmin       332.313781    796.500000           1.0     45.581936      0.057231   \n25%       438.895007   3247.750000           1.0    255.950253      0.084645   \n50%       466.321559   4418.500000           1.0    482.071018      0.107324   \n75%       480.090858   5451.500000           1.0    664.924645      0.123209   \nmax       578.014348  13033.000000           1.0   4126.459679      0.316616   \n\n        Feature_3235  Feature_3236  Feature_3237  Feature_3238       CLASS  \ncount          100.0    100.000000    100.000000    100.000000  100.000000  \nunique           NaN           NaN           NaN           NaN         NaN  \ntop              NaN           NaN           NaN           NaN         NaN  \nfreq             NaN           NaN           NaN           NaN         NaN  \nmean             0.0     28.416517      3.801596      0.110281    0.420000  \nstd              0.0      1.528245      0.245532      0.038825    0.496045  \nmin              0.0     22.407271      2.746720      0.057231    0.000000  \n25%              0.0     27.434784      3.675486      0.084645    0.000000  \n50%              0.0     28.445182      3.798834      0.107324    0.000000  \n75%              0.0     29.410854      3.960391      0.123209    1.000000  \nmax              0.0     31.625858      4.259145      0.316616    1.000000  \n\n[11 rows x 3240 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Feature_1</th>\n      <th>Feature_2</th>\n      <th>Feature_3</th>\n      <th>Feature_4</th>\n      <th>Feature_5</th>\n      <th>Feature_6</th>\n      <th>Feature_7</th>\n      <th>Feature_8</th>\n      <th>Feature_9</th>\n      <th>...</th>\n      <th>Feature_3230</th>\n      <th>Feature_3231</th>\n      <th>Feature_3232</th>\n      <th>Feature_3233</th>\n      <th>Feature_3234</th>\n      <th>Feature_3235</th>\n      <th>Feature_3236</th>\n      <th>Feature_3237</th>\n      <th>Feature_3238</th>\n      <th>CLASS</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>100</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>...</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.0</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.0</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n      <td>100.000000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>100</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>ID_100</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>36053.786458</td>\n      <td>36214.821667</td>\n      <td>13592.064411</td>\n      <td>0.396674</td>\n      <td>0.013031</td>\n      <td>0.063118</td>\n      <td>2.600435</td>\n      <td>0.390476</td>\n      <td>1.600435</td>\n      <td>...</td>\n      <td>459.472339</td>\n      <td>4561.901667</td>\n      <td>1.0</td>\n      <td>559.835599</td>\n      <td>0.110281</td>\n      <td>0.0</td>\n      <td>28.416517</td>\n      <td>3.801596</td>\n      <td>0.110281</td>\n      <td>0.420000</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>15327.976819</td>\n      <td>15355.686383</td>\n      <td>4319.053890</td>\n      <td>0.059999</td>\n      <td>0.002661</td>\n      <td>0.029819</td>\n      <td>0.290887</td>\n      <td>0.050831</td>\n      <td>0.290887</td>\n      <td>...</td>\n      <td>36.402913</td>\n      <td>1956.770922</td>\n      <td>0.0</td>\n      <td>503.131803</td>\n      <td>0.038825</td>\n      <td>0.0</td>\n      <td>1.528245</td>\n      <td>0.245532</td>\n      <td>0.038825</td>\n      <td>0.496045</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>6218.729167</td>\n      <td>6297.000000</td>\n      <td>3841.149780</td>\n      <td>0.218619</td>\n      <td>0.008883</td>\n      <td>0.028036</td>\n      <td>1.794599</td>\n      <td>0.303790</td>\n      <td>0.794599</td>\n      <td>...</td>\n      <td>332.313781</td>\n      <td>796.500000</td>\n      <td>1.0</td>\n      <td>45.581936</td>\n      <td>0.057231</td>\n      <td>0.0</td>\n      <td>22.407271</td>\n      <td>2.746720</td>\n      <td>0.057231</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>25357.187500</td>\n      <td>25519.000000</td>\n      <td>10880.779541</td>\n      <td>0.358070</td>\n      <td>0.011479</td>\n      <td>0.046821</td>\n      <td>2.528735</td>\n      <td>0.360423</td>\n      <td>1.528735</td>\n      <td>...</td>\n      <td>438.895007</td>\n      <td>3247.750000</td>\n      <td>1.0</td>\n      <td>255.950253</td>\n      <td>0.084645</td>\n      <td>0.0</td>\n      <td>27.434784</td>\n      <td>3.675486</td>\n      <td>0.084645</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>35002.104167</td>\n      <td>35176.500000</td>\n      <td>14217.937988</td>\n      <td>0.389202</td>\n      <td>0.012330</td>\n      <td>0.054013</td>\n      <td>2.645460</td>\n      <td>0.378006</td>\n      <td>1.645460</td>\n      <td>...</td>\n      <td>466.321559</td>\n      <td>4418.500000</td>\n      <td>1.0</td>\n      <td>482.071018</td>\n      <td>0.107324</td>\n      <td>0.0</td>\n      <td>28.445182</td>\n      <td>3.798834</td>\n      <td>0.107324</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>43567.947917</td>\n      <td>43737.500000</td>\n      <td>15871.476562</td>\n      <td>0.425203</td>\n      <td>0.013193</td>\n      <td>0.061849</td>\n      <td>2.774520</td>\n      <td>0.395462</td>\n      <td>1.774520</td>\n      <td>...</td>\n      <td>480.090858</td>\n      <td>5451.500000</td>\n      <td>1.0</td>\n      <td>664.924645</td>\n      <td>0.123209</td>\n      <td>0.0</td>\n      <td>29.410854</td>\n      <td>3.960391</td>\n      <td>0.123209</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>98935.750000</td>\n      <td>99113.000000</td>\n      <td>22896.642578</td>\n      <td>0.617324</td>\n      <td>0.022099</td>\n      <td>0.173813</td>\n      <td>3.291749</td>\n      <td>0.557652</td>\n      <td>2.291749</td>\n      <td>...</td>\n      <td>578.014348</td>\n      <td>13033.000000</td>\n      <td>1.0</td>\n      <td>4126.459679</td>\n      <td>0.316616</td>\n      <td>0.0</td>\n      <td>31.625858</td>\n      <td>4.259145</td>\n      <td>0.316616</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>11 rows × 3240 columns</p>\n</div>"},"metadata":{}},{"name":"stdout","text":"\nBlinded Test Set Info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 36 entries, 0 to 35\nColumns: 3239 entries, ID to Feature_3238\ndtypes: float64(3238), object(1)\nmemory usage: 911.1+ KB\nNone\n\nMissing Values:\nID              0\nFeature_1       0\nFeature_2       0\nFeature_3       0\nFeature_4       0\n               ..\nFeature_3234    0\nFeature_3235    0\nFeature_3236    0\nFeature_3237    0\nFeature_3238    0\nLength: 3239, dtype: int64\n\nDescriptive statistics:\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1458: RuntimeWarning: invalid value encountered in greater\n  has_large_values = (abs_vals > 1e6).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in less\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n/usr/local/lib/python3.11/dist-packages/pandas/io/formats/format.py:1459: RuntimeWarning: invalid value encountered in greater\n  has_small_values = ((abs_vals < 10 ** (-self.digits)) & (abs_vals > 0)).any()\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"            ID     Feature_1     Feature_2     Feature_3  Feature_4  \\\ncount       36     36.000000     36.000000     36.000000  36.000000   \nunique      36           NaN           NaN           NaN        NaN   \ntop     ID_101           NaN           NaN           NaN        NaN   \nfreq         1           NaN           NaN           NaN        NaN   \nmean       NaN  36381.127122  36541.277778  13631.158940   0.405920   \nstd        NaN  18798.136469  18838.271175   5512.018630   0.071102   \nmin        NaN   6743.222222   6797.000000   3338.486979   0.282432   \n25%        NaN  24438.947917  24569.000000  10102.937500   0.358557   \n50%        NaN  37753.875000  37940.000000  14892.043945   0.405953   \n75%        NaN  45658.666667  45823.500000  17086.297363   0.428828   \nmax        NaN  86333.625000  86559.000000  24383.398438   0.575246   \n\n        Feature_5  Feature_6  Feature_7  Feature_8  Feature_9  ...  \\\ncount   36.000000  36.000000  36.000000  36.000000  36.000000  ...   \nunique        NaN        NaN        NaN        NaN        NaN  ...   \ntop           NaN        NaN        NaN        NaN        NaN  ...   \nfreq          NaN        NaN        NaN        NaN        NaN  ...   \nmean     0.013211   0.065335   2.589071   0.393706   1.589071  ...   \nstd      0.002873   0.031112   0.328434   0.055438   0.328434  ...   \nmin      0.009294   0.030688   1.941702   0.313081   0.941702  ...   \n25%      0.011142   0.044113   2.413214   0.353324   1.413214  ...   \n50%      0.012502   0.055533   2.621135   0.381517   1.621135  ...   \n75%      0.014152   0.071170   2.830355   0.414398   1.830355  ...   \nmax      0.020351   0.153021   3.194060   0.525481   2.194060  ...   \n\n        Feature_3229  Feature_3230  Feature_3231  Feature_3232  Feature_3233  \\\ncount      36.000000     36.000000     36.000000          36.0     36.000000   \nunique           NaN           NaN           NaN           NaN           NaN   \ntop              NaN           NaN           NaN           NaN           NaN   \nfreq             NaN           NaN           NaN           NaN           NaN   \nmean      456.117598    456.117598   4583.398148           1.0    574.627871   \nstd        44.129095     44.129095   2381.690181           0.0    498.355891   \nmin       331.560473    331.560473    765.333333           1.0     52.077214   \n25%       440.013675    440.013675   3201.750000           1.0    272.506535   \n50%       455.950536    455.950536   4668.000000           1.0    398.628300   \n75%       483.804810    483.804810   5774.750000           1.0    754.194726   \nmax       536.422768    536.422768  10831.000000           1.0   2344.689595   \n\n        Feature_3234  Feature_3235  Feature_3236  Feature_3237  Feature_3238  \ncount      36.000000          36.0     36.000000     36.000000     36.000000  \nunique           NaN           NaN           NaN           NaN           NaN  \ntop              NaN           NaN           NaN           NaN           NaN  \nfreq             NaN           NaN           NaN           NaN           NaN  \nmean        0.109175           0.0     29.003962      3.825620      0.109175  \nstd         0.037869           0.0      1.645398      0.250235      0.037869  \nmin         0.062741           0.0     25.738961      3.208621      0.062741  \n25%         0.085810           0.0     27.747591      3.698666      0.085810  \n50%         0.101369           0.0     29.213753      3.850503      0.101369  \n75%         0.120206           0.0     29.938047      3.993069      0.120206  \nmax         0.216480           0.0     32.188301      4.222432      0.216480  \n\n[11 rows x 3239 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Feature_1</th>\n      <th>Feature_2</th>\n      <th>Feature_3</th>\n      <th>Feature_4</th>\n      <th>Feature_5</th>\n      <th>Feature_6</th>\n      <th>Feature_7</th>\n      <th>Feature_8</th>\n      <th>Feature_9</th>\n      <th>...</th>\n      <th>Feature_3229</th>\n      <th>Feature_3230</th>\n      <th>Feature_3231</th>\n      <th>Feature_3232</th>\n      <th>Feature_3233</th>\n      <th>Feature_3234</th>\n      <th>Feature_3235</th>\n      <th>Feature_3236</th>\n      <th>Feature_3237</th>\n      <th>Feature_3238</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>36</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>...</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>36.0</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>36.0</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n      <td>36.000000</td>\n    </tr>\n    <tr>\n      <th>unique</th>\n      <td>36</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>top</th>\n      <td>ID_101</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>freq</th>\n      <td>1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>NaN</td>\n      <td>36381.127122</td>\n      <td>36541.277778</td>\n      <td>13631.158940</td>\n      <td>0.405920</td>\n      <td>0.013211</td>\n      <td>0.065335</td>\n      <td>2.589071</td>\n      <td>0.393706</td>\n      <td>1.589071</td>\n      <td>...</td>\n      <td>456.117598</td>\n      <td>456.117598</td>\n      <td>4583.398148</td>\n      <td>1.0</td>\n      <td>574.627871</td>\n      <td>0.109175</td>\n      <td>0.0</td>\n      <td>29.003962</td>\n      <td>3.825620</td>\n      <td>0.109175</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>NaN</td>\n      <td>18798.136469</td>\n      <td>18838.271175</td>\n      <td>5512.018630</td>\n      <td>0.071102</td>\n      <td>0.002873</td>\n      <td>0.031112</td>\n      <td>0.328434</td>\n      <td>0.055438</td>\n      <td>0.328434</td>\n      <td>...</td>\n      <td>44.129095</td>\n      <td>44.129095</td>\n      <td>2381.690181</td>\n      <td>0.0</td>\n      <td>498.355891</td>\n      <td>0.037869</td>\n      <td>0.0</td>\n      <td>1.645398</td>\n      <td>0.250235</td>\n      <td>0.037869</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>NaN</td>\n      <td>6743.222222</td>\n      <td>6797.000000</td>\n      <td>3338.486979</td>\n      <td>0.282432</td>\n      <td>0.009294</td>\n      <td>0.030688</td>\n      <td>1.941702</td>\n      <td>0.313081</td>\n      <td>0.941702</td>\n      <td>...</td>\n      <td>331.560473</td>\n      <td>331.560473</td>\n      <td>765.333333</td>\n      <td>1.0</td>\n      <td>52.077214</td>\n      <td>0.062741</td>\n      <td>0.0</td>\n      <td>25.738961</td>\n      <td>3.208621</td>\n      <td>0.062741</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>NaN</td>\n      <td>24438.947917</td>\n      <td>24569.000000</td>\n      <td>10102.937500</td>\n      <td>0.358557</td>\n      <td>0.011142</td>\n      <td>0.044113</td>\n      <td>2.413214</td>\n      <td>0.353324</td>\n      <td>1.413214</td>\n      <td>...</td>\n      <td>440.013675</td>\n      <td>440.013675</td>\n      <td>3201.750000</td>\n      <td>1.0</td>\n      <td>272.506535</td>\n      <td>0.085810</td>\n      <td>0.0</td>\n      <td>27.747591</td>\n      <td>3.698666</td>\n      <td>0.085810</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>NaN</td>\n      <td>37753.875000</td>\n      <td>37940.000000</td>\n      <td>14892.043945</td>\n      <td>0.405953</td>\n      <td>0.012502</td>\n      <td>0.055533</td>\n      <td>2.621135</td>\n      <td>0.381517</td>\n      <td>1.621135</td>\n      <td>...</td>\n      <td>455.950536</td>\n      <td>455.950536</td>\n      <td>4668.000000</td>\n      <td>1.0</td>\n      <td>398.628300</td>\n      <td>0.101369</td>\n      <td>0.0</td>\n      <td>29.213753</td>\n      <td>3.850503</td>\n      <td>0.101369</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>NaN</td>\n      <td>45658.666667</td>\n      <td>45823.500000</td>\n      <td>17086.297363</td>\n      <td>0.428828</td>\n      <td>0.014152</td>\n      <td>0.071170</td>\n      <td>2.830355</td>\n      <td>0.414398</td>\n      <td>1.830355</td>\n      <td>...</td>\n      <td>483.804810</td>\n      <td>483.804810</td>\n      <td>5774.750000</td>\n      <td>1.0</td>\n      <td>754.194726</td>\n      <td>0.120206</td>\n      <td>0.0</td>\n      <td>29.938047</td>\n      <td>3.993069</td>\n      <td>0.120206</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>NaN</td>\n      <td>86333.625000</td>\n      <td>86559.000000</td>\n      <td>24383.398438</td>\n      <td>0.575246</td>\n      <td>0.020351</td>\n      <td>0.153021</td>\n      <td>3.194060</td>\n      <td>0.525481</td>\n      <td>2.194060</td>\n      <td>...</td>\n      <td>536.422768</td>\n      <td>536.422768</td>\n      <td>10831.000000</td>\n      <td>1.0</td>\n      <td>2344.689595</td>\n      <td>0.216480</td>\n      <td>0.0</td>\n      <td>32.188301</td>\n      <td>4.222432</td>\n      <td>0.216480</td>\n    </tr>\n  </tbody>\n</table>\n<p>11 rows × 3239 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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\n"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"#import libraries\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T10:46:15.510749Z","iopub.execute_input":"2025-05-31T10:46:15.511426Z","iopub.status.idle":"2025-05-31T10:46:15.839304Z","shell.execute_reply.started":"2025-05-31T10:46:15.511393Z","shell.execute_reply":"2025-05-31T10:46:15.838748Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# 1. Drop ID and separate target\nX_train = train_df.drop(columns=[\"ID\", \"CLASS\"])\ny_train = train_df[\"CLASS\"]\n\nX_test = test_df.drop(columns=[\"ID\", \"CLASS\"])\ny_test = test_df[\"CLASS\"]\n\nX_blinded = blinded_test_df.drop(columns=[\"ID\"])\n\n# Store IDs\ntrain_ids = train_df[\"ID\"]\ntest_ids = test_df[\"ID\"]\nblinded_ids = blinded_test_df[\"ID\"]\n\n# 2. Handle inf values before preprocessing\nX_train.replace([np.inf, -np.inf], np.nan, inplace=True)\nX_test.replace([np.inf, -np.inf], np.nan, inplace=True)\nX_blinded.replace([np.inf, -np.inf], np.nan, inplace=True)\n\n# 3. Define numeric preprocessing pipeline\nnumeric_features = X_train.columns.tolist()\nnumeric_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"mean\")),\n    (\"scaler\", StandardScaler())\n])\n\npreprocessor = ColumnTransformer([\n    (\"num\", numeric_pipeline, numeric_features)\n])\n\n# 4. Apply preprocessing\nX_train_processed = preprocessor.fit_transform(X_train)\nX_test_processed = preprocessor.transform(X_test)\nX_blinded_processed = preprocessor.transform(X_blinded)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T10:46:23.756316Z","iopub.execute_input":"2025-05-31T10:46:23.757088Z","iopub.status.idle":"2025-05-31T10:46:24.014005Z","shell.execute_reply.started":"2025-05-31T10:46:23.757055Z","shell.execute_reply":"2025-05-31T10:46:24.013260Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"# import libraries\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import StratifiedKFold, GridSearchCV\nfrom sklearn.metrics import accuracy_score, roc_auc_score, recall_score, precision_score, f1_score, confusion_matrix\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T10:46:39.209114Z","iopub.execute_input":"2025-05-31T10:46:39.209402Z","iopub.status.idle":"2025-05-31T10:46:39.553652Z","shell.execute_reply.started":"2025-05-31T10:46:39.209379Z","shell.execute_reply":"2025-05-31T10:46:39.553132Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#utility to calculate all required metrics\n\ndef evaluate_model(model, X, y_true, dataset_name=\"Test\"):\n    y_pred = model.predict(X)\n    y_prob = model.predict_proba(X)[:, 1]\n\n    accuracy = accuracy_score(y_true, y_pred)\n    auc = roc_auc_score(y_true, y_prob)\n    recall = recall_score(y_true, y_pred)\n    f1 = f1_score(y_true, y_pred)\n\n    cm = confusion_matrix(y_true, y_pred)\n    tn, fp, fn, tp = cm.ravel()\n    specificity = tn / (tn + fp)\n\n    print(f\"\\n{dataset_name} Evaluation for {model.__class__.__name__}\")\n    print(f\"Accuracy    : {accuracy:.4f}\")\n    print(f\"AUROC       : {auc:.4f}\")\n    print(f\"Sensitivity : {recall:.4f}\")\n    print(f\"Specificity : {specificity:.4f}\")\n    print(f\"F1 Score    : {f1:.4f}\")\n    \n\n# Prepare stratified 5-fold CV\ncv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T10:46:55.249527Z","iopub.execute_input":"2025-05-31T10:46:55.250241Z","iopub.status.idle":"2025-05-31T10:46:55.256111Z","shell.execute_reply.started":"2025-05-31T10:46:55.250216Z","shell.execute_reply":"2025-05-31T10:46:55.255289Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"#logistic regression\n\nlog_reg = LogisticRegression(max_iter=1000, solver='liblinear')\nlog_reg.fit(X_train_processed, y_train)\nevaluate_model(log_reg, X_test_processed, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T10:47:06.809978Z","iopub.execute_input":"2025-05-31T10:47:06.810236Z","iopub.status.idle":"2025-05-31T10:47:07.361734Z","shell.execute_reply.started":"2025-05-31T10:47:06.810215Z","shell.execute_reply":"2025-05-31T10:47:07.361079Z"}},"outputs":[{"name":"stdout","text":"\nTest Evaluation for LogisticRegression\nAccuracy    : 0.5900\nAUROC       : 0.6466\nSensitivity : 0.4524\nSpecificity : 0.6897\nF1 Score    : 0.4810\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# random forest\n\nrf_grid = {\n    \"n_estimators\": [100],\n    \"max_depth\": [10, 20],\n    \"min_samples_split\": [2, 5]\n}\n\nrf_model = GridSearchCV(RandomForestClassifier(random_state = 42), rf_grid, cv = cv, scoring = 'roc_auc', n_jobs = -1 )\nrf_model.fit(X_train_processed, y_train)\nevaluate_model(rf_model.best_estimator_, X_test_processed, y_test)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T10:47:20.462025Z","iopub.execute_input":"2025-05-31T10:47:20.462708Z","iopub.status.idle":"2025-05-31T10:47:28.000498Z","shell.execute_reply.started":"2025-05-31T10:47:20.462686Z","shell.execute_reply":"2025-05-31T10:47:27.999805Z"}},"outputs":[{"name":"stdout","text":"\nTest Evaluation for RandomForestClassifier\nAccuracy    : 0.6300\nAUROC       : 0.6708\nSensitivity : 0.3095\nSpecificity : 0.8621\nF1 Score    : 0.4127\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# XGBoost (with tuning)\n\nxgb_grid = {\n    \"n_estimators\": [100],\n    \"max_depth\": [3,5],\n    \"learning_rate\": [0.1, 0.05]\n}\n\nxgb_model = GridSearchCV(XGBClassifier(use_label_encoder = False, eval_metric = 'logloss'), xgb_grid, cv = cv, scoring = 'roc_auc', n_jobs = -1)\nxgb_model.fit(X_train_processed, y_train)\nevaluate_model(xgb_model.best_estimator_, X_test_processed, y_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T10:47:38.946959Z","iopub.execute_input":"2025-05-31T10:47:38.947207Z","iopub.status.idle":"2025-05-31T10:49:45.464418Z","shell.execute_reply.started":"2025-05-31T10:47:38.947191Z","shell.execute_reply":"2025-05-31T10:49:45.463458Z"}},"outputs":[{"name":"stdout","text":"\nTest Evaluation for XGBClassifier\nAccuracy    : 0.6100\nAUROC       : 0.6326\nSensitivity : 0.3571\nSpecificity : 0.7931\nF1 Score    : 0.4348\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# ======================= Final Class-Probability CSVs ==========================\nsave_probabilities_csv(xgb_best, X_train_processed, train_ids, \"train_predictions.csv\")\nsave_probabilities_csv(xgb_best, X_test_processed, test_ids, \"test_predictions.csv\")\nsave_probabilities_csv(xgb_best, X_blinded_processed, blinded_ids, \"blinded_test_predictions.csv\")\n\n# ======================= Results Table ==========================\nprint(\"\\nFinal Evaluation Results (Train & Test Sets):\\n\")\nresults_df = pd.DataFrame([\n    {\n        \"Model\": model,\n        \"Dataset\": dataset,\n        **metrics\n    }\n    for model, model_results in results.items()\n    for dataset, metrics in model_results.items()\n])\nprint(results_df.round(4))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-31T10:56:56.608200Z","iopub.execute_input":"2025-05-31T10:56:56.608615Z","iopub.status.idle":"2025-05-31T10:56:56.731747Z","shell.execute_reply.started":"2025-05-31T10:56:56.608592Z","shell.execute_reply":"2025-05-31T10:56:56.730954Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1868138775.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ======================= Final Class-Probability CSVs ==========================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msave_probabilities_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"train_predictions.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msave_probabilities_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"test_predictions.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msave_probabilities_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxgb_best\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_blinded_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblinded_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"blinded_test_predictions.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'save_probabilities_csv' is not defined"],"ename":"NameError","evalue":"name 'save_probabilities_csv' is not defined","output_type":"error"}],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}